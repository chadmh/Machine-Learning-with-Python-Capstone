{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4. Pretrained Networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN5FlyckFflXQzXUPoQorrR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chadmh/Short-Hands-on-Tutorial-for-Deep-Learning-in-Tensorflow/blob/master/4_Pretrained_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2dRtsJCX1gM"
      },
      "source": [
        "# 4.1 Adapting Pre-Trained CNNs to Image Processing Tasks\n",
        "\n",
        "While it might be satisfying to create a CNN from scratch, in practice one will often get better performance from customizing an industry standard model.  One such network is ResNet50.  This is a 50-layer CNN [published in 2105 by Kaiming He, et al](https://arxiv.org/abs/1512.03385). The code used to load and preprocess the MNIST data is similar to earlier notebooks; however, because ResNet50 expects a 3 channel (color) image with a size of at least 32 x 32 pixels, the preprocessing code will need to convert the image from 28 x 28 x 1 to 32 x 32 x 3.  This can be done by zero padding the original images and replicating them across 3 channels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m41igqcPYBIh",
        "outputId": "e4e03e1e-2d33-49e6-ee31-a6239e790891"
      },
      "source": [
        "# Import the needed tensorflow components\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Load the MNIST dataset.  Load checks whether the dataset is locally available and downloads it from \n",
        "# its official repository if at http://yann.lecun.com/exdb/mnist if it cannot be found.\n",
        "(train, test), info = tfds.load('mnist',                  # Pick the MNIST dataset\n",
        "                                 split=['train', 'test'], # Load both the training and testing parts of the dataset\n",
        "                                 with_info=True,          # Generate summary information about the dataset\n",
        "                                 as_supervised=True)      # return both the inputs and labels as a tuple\n",
        "\n",
        "print(info.description)\n",
        "print(info.splits)\n",
        "\n",
        "# Define the data preprocessing pipeline.  For MNIST, the only needed preprocessing is to convert from unit8 to \n",
        "# float.  Other data sets are likely more extensive.\n",
        "def preprocess_data(input, label):\n",
        "  # Convert unit8 to real on [0, 1]\n",
        "  input = tf.cast(input, tf.float32) / 255.0\n",
        "\n",
        "  # Apply zero padding to make the image 32 x 32; center original image\n",
        "  input = tf.image.pad_to_bounding_box(input, 2, 2, 32, 32)\n",
        "\n",
        "  # Make 1 channel image 3 channels\n",
        "  input = tf.tile(input, tf.constant([1,1,3], tf.int32))\n",
        "\n",
        "  return input, label\n",
        "\n",
        "# Assign the preprocessing pipeline to each dataset: train and test\n",
        "train = train.map(preprocess_data)\n",
        "test = test.map(preprocess_data)\n",
        "\n",
        "# Tell each dataset how many images it will load at once for processing\n",
        "BATCH_SIZE=128\n",
        "train = train.batch(BATCH_SIZE)\n",
        "test = test.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The MNIST database of handwritten digits.\n",
            "{'test': <tfds.core.SplitInfo num_examples=10000>, 'train': <tfds.core.SplitInfo num_examples=60000>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHXXlPyIYqMk"
      },
      "source": [
        "This notebook will demonstrate customizing the ResNet50 model for the MNIST dataset.  In reality, the weights we will use for this instantiation of ResNet50 were trained on natural photos rather than digits, so performance may suffer, but such will be a good learning opportunity.\n",
        "\n",
        "The basic approach is to replace the final layer of the trained model with our own 10 neuron layer and then to retrain just the final layer while keeping all other parameters locked. The advantage here is that training large models takes a significant amount of time.  By locking the pretrained part, we retain all the useful edge recognition and other kernals and save a huge amount of training time.  Replacing the last layer with our custom layer allows us to fine-tune the model to our unique labels and create a high-performance custom model for our situation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEWs9m15bzte",
        "outputId": "49b06388-4a37-4ac0-f9bb-36d2beb82703"
      },
      "source": [
        "resnet_model = tf.keras.models.Sequential()\n",
        "resnet_model.add(tf.keras.applications.resnet50.ResNet50(\n",
        "    include_top=False,\n",
        "    pooling='avg',\n",
        "    input_shape=(32, 32, 3),\n",
        "    weights='imagenet',\n",
        "    ))\n",
        "resnet_model.add(tf.keras.layers.Dense(10))\n",
        "resnet_model.layers[0].trainable = False\n",
        "resnet_model.compile(optimizer='adam', \n",
        "                     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
        "                     metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "resnet_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Functional)        (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,608,202\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roMKNEl7npV9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxjLR6QcnpZw"
      },
      "source": [
        "Training is done using the fit function just as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2i15_4kcrmL",
        "outputId": "95e54868-f250-4945-8984-0307252945b4"
      },
      "source": [
        "resnet_model.fit(train, epochs=2, validation_data=test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "469/469 [==============================] - 165s 344ms/step - loss: 1.0506 - sparse_categorical_accuracy: 0.7114 - val_loss: 0.6415 - val_sparse_categorical_accuracy: 0.8362\n",
            "Epoch 2/2\n",
            "469/469 [==============================] - 156s 332ms/step - loss: 0.5952 - sparse_categorical_accuracy: 0.8362 - val_loss: 0.4817 - val_sparse_categorical_accuracy: 0.8703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1f6be57a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBP6ZZXWn3Re"
      },
      "source": [
        "Using the fine-tuned professional model, the performance actually drops relative to the models in [Notebook1](https://colab.research.google.com/github/chadmh/Short-Hands-on-Tutorial-for-Deep-Learning-in-Tensorflow/blob/master/1_Introduction.ipynb) and [Notebook 3](https://colab.research.google.com/github/chadmh/Short-Hands-on-Tutorial-for-Deep-Learning-in-Tensorflow/blob/master/3_Convolutional_Neural_Networks.ipynb).  While one might initially be surprised by this turn of events, the reason is actually quite simple.  The pretrained weights that we used for the ResNet50 model were trained using the [ImageNet dataset](https://image-net.org/index.php). This dataset focuses on a broad array of animals, plants, people and things, but not digits.  It also is optimized for larger images with a default input size of (224, 224, 3).  The issue could be resolved by retraining from scratch on digit data.  The model performs much better when applied to photographic images as that is what is used in its training data.\n",
        "\n",
        "This performance loss, however, clearly shows that simply grabbing and using an industry-standard model without knowing its assumptions and training biases will lead to sub-standard performance.  Newer or larger does not necessarily mean better in the context of a specific machine learning problem.  Knowing which model will apply well in which situation is a matter of reading the scientific literature and developing hands-on experience.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmWy9SZWrcWT"
      },
      "source": [
        "# 4.2 Applications of CNNs to production pipelines\n",
        "\n",
        "CNNs typically attempt to classify an image as a single item.  In general an image may contain multiple items of interest.  For example, a security camera may take an image containing people, bikes, dogs and cars.  Applying the CNN to the entire image at once, therefore, tends to confuse the network as it sees features associated with multiple classes.\n",
        "\n",
        "One approach to resolve this issue is to split the large image into smaller windows and process each with the CNN.  This reduces the likelihood of having multiple classes of objects in a single input.  The window size and overlap is application dependent. The system tracks which windows flag a high-confidence hit on a class of interest and then localize the object based on the window position.  This approach scales to large and varied images but can suffer from poor execution speed as the system must process and book-keep the individual images. This can mean that the original image is processed multiple times due to overlap and scaling as the system tries to match the input images to the trained model. \n",
        "\n",
        "A more modern approach is to treat the image analysis as a regression rather than classification problem.  This is the approach taken by YOLO (You Only Look Once) networks as discussed in the next notebook."
      ]
    }
  ]
}