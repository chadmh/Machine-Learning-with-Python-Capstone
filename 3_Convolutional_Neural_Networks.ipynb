{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Convolutional Neural Networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOmOh3oUhgo3Z5bbV7XToNV"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kPrirL6nx0d"
      },
      "source": [
        "# 3.1 Convolutional Neural Networks\n",
        "\n",
        "Basic deep neural network layers can be represented by a linear transformation and a non-linear activation function:\n",
        "\n",
        "> *y = f(w * x + b)*\n",
        "\n",
        "where w is a matrix of trainable parameters, and b is a vector of trainable parameters.  This type of neural network layer is often called a dense, or fully-connected, layer.\n",
        "\n",
        "An issue arises when applying these networks to data with important spatial relationships, such as images or volumetric data.  As we saw in the [Introduction to Tensorflow with MNIST](https://colab.research.google.com/drive/1xi8_50VAG_awaMuRRkxJZzQs8qGnaCtv), these spatial relationships are lost when the input image is flattened.\n",
        "\n",
        "Convolutional neural networks extend the basic deep network idea by implementing what is known as a convolutional layer.  A convolutional layer is a implemented as a set of MxM kernal matrices which are then convolved with the input data.  The training of the convolutional layer then consists of choosing the best values for each kernal matrix.\n",
        "\n",
        "Some extremely simple examples of kernal matrices include [-1, 0, 1] and its transpose which are used for vertical and horizontal edge detection, respectively.  In CNNs the training process designs the kernals that best allow the model to minimize its loss function.\n",
        "\n",
        "After convolving the image with the kernals in one or more layers, a CNN typically applies a pooling layer.  A pooling layer's job is to collect the most relevent information from the output of each kernal.  It is computed by collecting the most relevent cell (e.g. max value) of an NxN window, moving (striding) K pixels and repeating.\n",
        "\n",
        "### 3.1.1 CNN Basic Architecture\n",
        "\n",
        "The basic architecture of a CNN is to apply multiple layers of the convolution/pooling operation and to then pass the output to a set of dense layers for interpretation.\n",
        "\n",
        "CNNs are a popular tool for analyzing image data.  In this notebook, a simple CNN will be demonstrated on the MNIST dataset.  The code to load the dataset and setup the processing pipeline is equivalent to [notebook 1](https://colab.research.google.com/drive/1xi8_50VAG_awaMuRRkxJZzQs8qGnaCtv#scrollTo=qBT-P-4q4HtT)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBbDCAzgJWJn",
        "outputId": "39fd803c-11bc-498b-fcf3-1fb59558ca10"
      },
      "source": [
        "# Import the needed Tensorflow components\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Load the MNIST dataset.  Load checks whether the dataset is locally available and downloads it from \n",
        "# its official repository at http://yann.lecun.com/exdb/mnist if it cannot be found.\n",
        "(train, test), info = tfds.load('mnist',                  # Pick the MNIST dataset\n",
        "                                 split=['train', 'test'], # Load both the training and testing parts of the dataset\n",
        "                                 with_info=True,          # Generate summary information about the dataset\n",
        "                                 as_supervised=True)      # return both the inputs and labels as a tuple\n",
        "\n",
        "print(info.description)\n",
        "print(info.splits)\n",
        "\n",
        "# Define the data preprocessing pipeline.  For MNIST, the only needed preprocessing is to convert from unit8 to \n",
        "# float.  Other data sets are likely more extensive.\n",
        "def preprocess_data(input, label):\n",
        "  # Convert unit8 to real on [0, 1]\n",
        "  input = tf.cast(input, tf.float32) / 255.0\n",
        "  return input, label\n",
        "\n",
        "# Assign the preprocessing pipeline to each dataset: train and test\n",
        "train = train.map(preprocess_data)\n",
        "test = test.map(preprocess_data)\n",
        "\n",
        "# Tell each dataset how many images it will load at once for processing\n",
        "BATCH_SIZE=128\n",
        "train = train.batch(BATCH_SIZE)\n",
        "test = test.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The MNIST database of handwritten digits.\n",
            "{'test': <tfds.core.SplitInfo num_examples=10000>, 'train': <tfds.core.SplitInfo num_examples=60000>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLV4Fz3tJ9nn"
      },
      "source": [
        "Now that the data pipeline is set up, it is time to design the CNN.  In this simple network, we have two convolution / pooling layers.  Each convolution layer has 8 3x3 kernals.  Setting the padding parameter to 'same' zero pads the output so that the convolution result is still 28 x 28 pixels.\n",
        "\n",
        "The max pooling layer divides the 28 x 28 output from each of the 8 kernals into 2 x 2 blocks and keeps just the maximum pixel value from each block.  The data size is now 14 x 14 x 8.\n",
        "\n",
        "The next convolution layer reads in the 14 x 14 x 8 array.  The 8 kernal outputs are simply treated as different channels of the data.  The next layer's convolution kernals are applied to each 14 x 14 array in the data, and the result is summed across channels.  2x2 Max pooling is applied just as before resulting in a 7 x 7 x 8 block of data for each image.\n",
        "\n",
        "The idea behind using multiple iterations of convolution / pooling is that the first iteration will capture basic features such as edges and lines, while later layers capture higher level features such as curves or digit fragments.  This concept follows the hierarchical neural system of the human visual cortex.\n",
        "\n",
        "After the final convolution / pooling iteration, the data block is flattened and passed to a dense network with ReLU activation and then output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yye5fPbjKKLf",
        "outputId": "74220b4a-d746-41ca-fd5a-098d617e1b23"
      },
      "source": [
        "# Specify a basic sequential neural network\n",
        "model = tf.keras.models.Sequential([\n",
        "                                   tf.keras.layers.Conv2D(8, 3, input_shape=(28, 28, 1), padding='same'), # Convolution with 8 3x3 kernals\n",
        "                                   tf.keras.layers.MaxPool2D(pool_size=(2, 2)),  # Keep max value of each 2x2 block\n",
        "                                   tf.keras.layers.Conv2D(8, 3, padding='same'), # Another convolution with 8 3x3 kernals\n",
        "                                   tf.keras.layers.MaxPool2D(pool_size=(2, 2)),  # Keep max value of each 2x2 block (data is 7x7x8)\n",
        "                                   tf.keras.layers.Flatten(),                    # Flatten 7x7x8 array into a 392 x 1 vector \n",
        "                                   tf.keras.layers.Dense(20, activation='relu'), # Hidden Layer: Define a layer with 20 neurons\n",
        "                                   tf.keras.layers.Dense(10)                     # Output Layer: Define a layer with a slot for each digit.\n",
        "                                   ])\n",
        "\n",
        "# Define the optimizing algorithm and optimizing matrix for the model\n",
        "model.compile(\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),              # Use the Adam optimizer to train the model\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), # Minimize the categorical crossentropy function in training\n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]                # Measure our overall accuracy to see how well we've trained\n",
        "              )\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 8)         80        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 14, 14, 8)         584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 8)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 392)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 20)                7860      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 8,734\n",
            "Trainable params: 8,734\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTCspt8DWfS-"
      },
      "source": [
        "Although the final model is more complicated than that of [Notebook 1](https://colab.research.google.com/drive/1xi8_50VAG_awaMuRRkxJZzQs8qGnaCtv#scrollTo=m-SrDXeLD5jq) the total number of trainable parameters is reduced from  nearly 16,000 to under 9,000.  At the same time, by capturing the spatial correlation of pixels, the model should perform better than a purely dense model like notebook 1.  Just as in Notebook 1, we train using the fit function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl5kfAzfRWFw",
        "outputId": "7e2aceb0-10e3-42ba-b8df-2bdb158a5f03"
      },
      "source": [
        "model.fit(train, epochs=2, validation_data=test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "469/469 [==============================] - 31s 64ms/step - loss: 0.5109 - sparse_categorical_accuracy: 0.8464 - val_loss: 0.1728 - val_sparse_categorical_accuracy: 0.9489\n",
            "Epoch 2/2\n",
            "469/469 [==============================] - 24s 51ms/step - loss: 0.1448 - sparse_categorical_accuracy: 0.9575 - val_loss: 0.1113 - val_sparse_categorical_accuracy: 0.9646\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe6aa76e550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGOiCBbTXFE_"
      },
      "source": [
        "After 2 epochs, the model accuracy is almost 96% compared with 92% for the dense network in Notebook 1.  This demonstrates that the CNN architecture is more efficient for image processing."
      ]
    }
  ]
}